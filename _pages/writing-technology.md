---
layout: page
title: "Writing Technology"
permalink: /writing-technology/
---
## GenAI Policy: An Overview

Generative AI (GenAI) based on Large Language Model (LLM) refers to a type of artificial intelligence that can understand, generate, and respond to human language. Examples include OpenAI’s ChatGPT, Anthropic’s Claude, and Google’s Gemini. In this course, you are permitted to use LLM-based GenAI for planning, organizing, outlining, brainstorming, and copy-editing your work for any major or minor assignment. However, you are not permitted to use GenAI for composition, writing, or content generation. In other words, the final product that you turn in should be at least 80% your work.

## When Using GenAI for Writing May Be a Good Idea:

0. When You Know How to Prompt Them
   
- In simple terms, LLM-based GenAI models respond to your requirements, but the level of precision and detail of your instructions could significantly impact the quality, accuracy, and usefulness of their output. Therefore, the ability to produce effective prompts, usually with specific scenarios and step-by-step instructions, ideally with examples, is essential to effective use of AI, resulting in the discipline of prompt engineering. For your reference, here is a database of [GenAI prompt samples developed by Google](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery).

1. Provide Helpful Contributions

- As Rationale 0 implies, the analogy of a project manager is illustrative of a fruitful relationship between you and GenAI. For writing tasks, this may be akin to hiring an intimate writing coach or a 24/7 copyeditor at a lesser price, though it does not necessarily reduce your workload or prevent biases (see section below). Motivated by thoughtful prompts, large language models can produce detailed brainstorming ideas and productive feedback for your writings.

2. Enhance Reflective Writing Process

- This class frames writing as a process with various stages, often [back and forth](https://writersworkshop.illinois.edu/resources-2/writer-resources/writing-processes/revising/), with different orientations given the purposes and audiences. At the same time, previous studies recognize students’ meaningful engagements with GenAI in their assignments [at different scales](https:/celt.uky.edu/student-ai-use-scale). Leveraging AI in tasks such as proofreading and reviewing could thus render a valuable process of consciously reflecting on your writing as you revise and edit it.

1. Foster Equity and Justice

- Language accessibility is an issue of equity and justice. For example, consider the Equal Educational Opportunities Act of 1974 that prompts schools to provide English language support for non-English-speaking students, an immediate response to the [legal efforts from a group of parents of Chinese students](https://en.wikipedia.org/wiki/Lau_v._Nichols). Therefore, using AI to consult about readings and writings could contribute to enhancing language accessibility in professional, academic, or non-native contexts.

4. Provide Research-backed Insights

- Whereas the best-known GenAI engines are not good at providing diverse, up-to-date, or even real academic sources for your research questions, institutions and corporations have developed tools targeting researchers that provide smart citations and literature overviews. The UKY has currently provided access to such tools, which you could check out [here](https://libguides.uky.edu/genai/resources). Note, however, they are usually stronger in journal articles but not in books because of the databases they draw from.

Acknowledging the advantages of using GenAI for writing does not render me an AI advocate. Based on the existing knowledge, below are the reasons I hold reservations for its use.

## Why You Want to be Cautious:

1. Privacy Concerns

- Privacy concerns are typically among the top 3 reasons to reject GenAI. Unless you have set up otherwise, all the data you send to your AI bots will be collected to train their future models. In an age when your personal contact info is [floating everywhere](https://support.google.com/websearch/answer/12719076?hl=en) and being processed as a transaction item, you may want to be careful about what you feed your chatbots.

2. Possibly More Workload (!)

- Countering the pro-AI reasoning, sometimes GenAI is simply not worth the time if you have specific standards. Their output often needs multiple rounds of adjustment and fine-tuning to match specific assignment requirements, course objectives, and project scopes. In the worst scenario, they keep [falsifying information without admitting it](https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/). Remember the analogy of project management? Imagine that you are leading a teammate who has a good attitude but stubbornly refuses to change, is very forgetful, and occasionally puts on airs: GenAI is not a human; they cannot hold accountability for you.

3. What About Style?

- Particularly in this classroom, we value original voice. Yet, texts generated by large language models predict less diverse styles and homogeneous language patterns, leading to a “monoculture” of generated content. Beyond this classroom, relying on GenAI-generated writing might put you in a risky position when reviewers use [AI detectors](https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/) to filter your papers, applications, and other works, even though none of these tools promise 100% accuracy.

4. GenAI Perpetuates Biases

- LLM-based GenAI are trained on human-generated texts and, ironically, GenAI-generated texts that mimic human-generated texts. As human writings are [not free from biases](https://www.npr.org/sections/coronavirus-live-updates/2020/12/18/948176807/stanford-apologizes-after-vaccine-allocation-leaves-out-nearly-all-medical-resid), these biases overtly or covertly pervade the output from GenAI on the first day. Consider, for example, the 2024 finding that ChatGPT and Gemini hold [racist stereotypes](https://www.theguardian.com/technology/2024/mar/16/ai-racism-chatgpt-gemini-bias) about speakers of African American Vernacular English. Uncritically using AI, then, could risk introducing unseen biases into your writing. If you are not sure about how to read your AI bots’ suggestions, [asking for feedback](https://writersworkshop.web.illinois.edu/resources-2/writer-resources/writing-processes/asking-for-feedback/) from me is never a bad idea.

5. Ethical Concerns

- Other than issues of privacy and biases stated above, using GenAI tools implicates [a range of ethical concerns](https://onlineteaching.umich.edu/articles/ethical-considerations-of-using-genai-tools/), including infringing copyrighted content and causing harmful environmental impact. In addition, bear in mind that someone has to moderate and annotate the data before machine processing, which involves [significant labor issues](https://irlpodcast.org/season7/episode2/). If any of these concerns resonate with you, think twice about whether your next AI operation is worth it before you proceed.

In general, this classroom permits a transparent, thoughtful, and ethical use of GenAI for your writing.

## Note

Note: Part of the overview comes from the “[AI Course Policy Examples](https://celt.uky.edu/ai-course-policy-examples)” of CELT UKY.